{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA Men's Basketball Milestone Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "\n",
    "From 2002-2019,  teams in the regular season  of NCAA basketball games won 51,821 of their home games but only won  26,757 games  of their away games, giving a winning percentage of 60.6 when playing at home versus xxx when playing at away or neutral locations.  This home court advantage was further confirmed with a Tukey HSD test that showed that there is a statistically significant difference between the pairs home and away games, the pairs home and neutral games, versus the  pair away and neutral games.\n",
    "\n",
    "\n",
    "Many articles have explained that the reason for  a team’s home-court success is the presence of fans and the arena as opposed to the fact that they are simply the better team in a particular matchup. Assuming this is the case, the odds are already stacked against a visiting team, when playing these basketball matches. This report tries to analyse  some of the differences between playing on the road and playing at home and sees how to optimize the in game statistics for the visiting team.\n",
    "\n",
    "\n",
    "In this report, the average points posted for the winning team when playing at home  was xx % higher than  when playing away or at a neutral location, the average three-pointers scored by the winning team was xx% higher when playing at home versus when playing away or at a neutral location  , the turnover conceded by the winning team was xxx% when playing at home than when playing away or at a neutral location , three-pointers  posted by the winning teams was xxx%.higher when playing at home than when playing away or at a neutral location\n",
    "Evaluations of the in game statistics confirmed that there was a strong correlation between the field goals made and assist for the winning teams,  while there were weak correlations between turnovers conceded to the winning score by the winning team.\n",
    "\n",
    "The  teams with the highest winning percentages in the seasons  2003 -2019  were Kansas and Gonzaga , and their average winning scores in matches when compared to each other, showed that the difference in their winning scores was not statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- \n",
    "__Table of Contents__\n",
    "\n",
    "[Abstract](#abstract)\n",
    "\n",
    "[Introduction](#introduction)\n",
    "\n",
    "[Objective](#objective)\n",
    "\n",
    "[Dataset](#dataset)\t\n",
    "\n",
    "[Data Type] (#data Type)\n",
    "\n",
    "[Data Cleaning & Wrangling] (#data cleaning & wrangling)\n",
    "\n",
    "[Handling Missing Data](#handling Missing Data)\n",
    "\n",
    "[Exploratory Data Analysis](#exploratory Data Analysis)\n",
    "\n",
    "[Data Statistics](#data statistics)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The phenomenon of home field advantage is nothing new in the world of sports .  Home teams generally have the advantage of having the support of larger, more enthusiastic crowds, and it has been suggested in some studies, that it is the home court atmosphere  that enhances the home teams opportunities for winning matches.\n",
    "\n",
    "---\n",
    "\n",
    "# Objective\n",
    "\n",
    "The goal of my project is to study game factors that affect a home team winning an NCAA Division 1 Men’s basketball game, and likewise affect an away team losing a match. The information derived from these analysis can help a basketball coach tune his game play tactics and thereby increase his odds of winning a game when playing at an away location.\n",
    "\n",
    "---\n",
    "\n",
    "# Dataset \n",
    "\n",
    "The dataset for this analysis will be obtained  from Kaggle [Dataset](https://www.kaggle.com/c/mens-machine-learning-competition-2019/data \"Dataset\").This data is associated with an annual competition sponsored by Google.The datasets explored in our analysis were from the tables\n",
    "\n",
    "### Code 1: Dataset\n",
    "    \n",
    "   * RegularSeasonCompactResults.csv \n",
    "``` python\n",
    "capstone= pd.read_csv(\"mens-machine-learning-competition-2019/Prelim2019_RegularSeasonDetailedResults.csv\")\n",
    "```\n",
    "   * TeamSpellings.csv \n",
    "\n",
    "``` python\n",
    "   cap = pd.read_csv(\"mens-machine-learning-competition-2019/TeamSpellings.csv\",encoding =\"latin\")\n",
    "```\n",
    "> _The regular season file identifies the game by game results for regular season matches for the years 2003  - 2019, while the teamspellings file is used to correlate TeamID numbers with their associated names_. \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for the regular season games consists of 87,366 data points  for 350 college basketball teams  playing in the NCAA since 2002. The dataset includes 34 variables such as number of assists, three-point percentages per game, win and loss records per season, location of matches played, etc.\n",
    "### Code 2: Dataset Summary\n",
    "```python\n",
    "capstone.shape\n",
    " (87366, 34)\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the variables in the dataset is provided in the table below, with the designation that a column that begins with **W** or **L** refers to the winning or losing team:\n",
    "### Code 3: Dataset Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python capstone.head()```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![capstone](https://github.com/dreamtx01/Springboard/blob/master/Folders/Capstone%20Project%201/Image/capstone.head.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "WTeamID - this identifies the id number of the team that won the game.\n",
    "\n",
    "WScore - this identifies the number of points scored by the winning team.\n",
    "\n",
    "LTeamID - this identifies the id number of the team that lost the game.\n",
    "\n",
    "LScore - this identifies the number of points scored by the losing team. \n",
    "\n",
    "WLoc - this identifies the \"location\" of the winning team. The home team is given the value”H”, while the visiting\n",
    "team is given the value “A”, and the value “N” is given to a match played on a neutral location. \n",
    "\n",
    "NumOT - this indicates the number of overtime periods in the game, an integer 0 or higher.\n",
    "\n",
    "WFGA - field goals attempted (by the winning team)\n",
    "\n",
    "WFGM3 - three pointers made (by the winning team)\n",
    "\n",
    "WFGA3 - three pointers attempted (by the winning team)\n",
    "\n",
    "WFTM - free throws made (by the winning team)\n",
    "\n",
    "WFTA - free throws attempted (by the winning team)\n",
    "\n",
    "WOR - offensive rebounds (pulled by the winning team)\n",
    "\n",
    "WDR - defensive rebounds (pulled by the winning team)\n",
    "\n",
    "WAst - assists (by the winning team)\n",
    "\n",
    "WTO - turnovers committed (by the winning team)\n",
    "\n",
    "WStl - steals (accomplished by the winning team)\n",
    "\n",
    "WBlk - blocks (accomplished by the winning team)\n",
    "\n",
    "WPF - personal fouls committed (by the winning team)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Wrangling\n",
    "\n",
    "Before beginning analysis of the data, it is essential to explore there is no missing data value in our dataset. It is also essential that all data in our table was of the correct data type. This upfront work will give more confidence  in  interrogating the data  and would allow better conclusions  to be made as regards the dataset. The  libraries used for the data cleaning and wrangling of the data sets are:\n",
    " numpy for scientific computing of the numerical arrays\n",
    "pandas for data analysis and manipulation ,\n",
    "matplotlib for visualization\n",
    "### Code 4: Library Import\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Type \n",
    "\n",
    "The next step in the data wrangling stage was to determine the type of data type in the dataset.  As can be observed in the table below, there are 87,366  entries, with no missing values in any of the 34 columns. Additionally, all but one column takes  integer values , whereas the lone column (WLoc)  takes a string entry. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 5: Data Type\n",
    "\n",
    "```python \n",
    "capstone.info```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![datatype](https://github.com/dreamtx01/Springboard/blob/master/Folders/Capstone%20Project%201/Image/datatype.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact from the data set description we know that the WLoc column will take only three values each one representing the location of games played. To confirm the entry of the WLoc column we  call the unique () function on that column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 6: Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python capstone.WLoc.unique() ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Following the data wrangling of the data, the next step is to interrogate the dataset and ask a series of questions of the dataset. These questions will help identify the contributing factors affecting home games winning matches. The questions being asked of the data are :\n",
    "\n",
    "* Does a winning team score more points when playing at home, than when playing at either a neutral ground or an away ground?\n",
    "* Does a losing team score more points when playing at home, than when playing at either a neutral ground or an away ground?\n",
    "* Is there a difference in the amount of matches played at home, away or a neutral location?\n",
    "* What is the average variation in points scored for the winning team per season?\n",
    "* What is the average variation in three-points scored by the winning team when playing at home, away or a neutral location per season?\n",
    "* What is the average turnover by the winning team when playing at home, away or a neutral location per season?\n",
    "* What is the ranking of the top 15 teams based on the winning percentage per season?\n",
    "* What is the ranking of the top 15 teams by the no. of points scored for all seasons irrespective of the number of matches played\n",
    "* What is the ranking of the teams by lowest no. of points scored for all seasons irrespective of the number of matches played\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Does a winning team score more points when playing at home, than when playing at either a neutral ground or an away ground?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 8: Box Plot - points scored by winning team at playing locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "fig,ax1 = plt.subplots(1,1)\n",
    "fig.set_size_inches(10,7)\n",
    "capstone_plot= sns.boxplot(data = capstone, x= 'WLoc',y ='WScore')\n",
    "ax1.set_title(\"Points Distribution\")\n",
    "ax1.set_xticklabels(['Neutral Ground',\"Home Ground\",\"Away Ground\" ])\n",
    "ax1.set_ylabel('Points Scored by Winning team')\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The box plots show that the average number of points for the winning team at their home ground is higher than the points scored when playing at either away or neutral grounds. This result will be further investigated in the statistical portion of the report.  This box plot confirms the phenomenon of home advantage being present for home teams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. **Does a losing team score more points when playing at home than when playing at either a neutral ground or an away ground?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 9: Box Plot - points scored by losing team at playing locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "capstone= pd.read_csv(\"mens-machine-learning-competition-2019/Prelim2019_RegularSeasonDetailedResults.csv\")\n",
    "cap = pd.read_csv(\"mens-machine-learning-competition-2019/TeamSpellings.csv\",encoding =\"latin\")\n",
    "fig,ax1 = plt.subplots(1,1)\n",
    "fig.set_size_inches(10,7)\n",
    "\n",
    "capstone_plot= sns.boxplot(data = capstone, x= 'WLoc',y ='LScore')\n",
    "\n",
    "ax1.set_title(\"Points Distribution\")\n",
    "ax1.set_xticklabels(['Neutral Ground',\"Home Ground\",\"Away Ground\" ])\n",
    "ax1.set_ylabel('Points Scored by Losing team')\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The plots seem to show that the losing teams scores more points when playing at an away ground versus when playing at their neutral or home ground.However, there seems to be no difference to the average number of points scored by the losing team when playing in either of the neutral or home locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **What is the difference in the amount of games played in either home, away or at a neutral location?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10: Bar Chart - Proportion of games played at different locations in all seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python pd.DataFrame(capstone.WLoc.value_counts())```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcharttable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python plt.figure(figsize=(10,10))\n",
    "sns.countplot(y = capstone[\"Season\"],hue=capstone[\"WLoc\"],\n",
    "              palette=[\"r\",\"g\",\"b\",\"c\",\"lime\",\"m\",\"y\",\"k\",\"gold\",\"orange\"])\n",
    "plt.title(\"Matches Played Per Season\")\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The proportion of all games played at home, away and in a neutral ground were all similar across all seasons.The graphs also show that more matches were played at home than at away and neutral locations in a given season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **What is the average variation in points scored for the winning team per season?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 11: Line Chart - Points scored per winning team per season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Home = capstone[capstone.WLoc == 'H']\n",
    "Away = capstone[capstone.WLoc == 'A']\n",
    "Neutral = capstone[capstone.WLoc == 'N']\n",
    "\n",
    "\n",
    "AvgH=Home.groupby(\"Season\").WScore.mean()\n",
    "\n",
    "AvgA=Away.groupby(\"Season\").WScore.mean()\n",
    "\n",
    "AvgN=Neutral.groupby(\"Season\").WScore.mean()```\n",
    "    \n",
    "A=plt.plot(AvgH.index,AvgH)\n",
    "B=plt.plot(AvgA.index,AvgA)\n",
    "C=plt.plot(AvgN.index,AvgN)\n",
    "\n",
    "\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Points Scored per Season')\n",
    "plt.title(' Points Scored per winning team', size=20)\n",
    "plt.legend([\"Home\", \"Away\",\"Neutral\"],loc=0)\n",
    "plt.show() \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points scored by winning team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "For all seasons the number of points scored by the winning team while playing at home is greater than points scored when playing at an away or a neutral location.  The data also shows that from 2015 there is a general upward trend in the points scored per season. Some suggestions for the uptick in scoring are that maybe teams are becoming more efficient in scoring, or it could also be that the rules of basketball have changed to favor the scoring team. Another observation from this analysis is that in 2015 there was a dip in scoring in all locations. This observation would require further investigation as to why there was a specific drop in scoring this particular year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **What is the average variation in three-pointers scored by the winning team when playing at home, away or a neutral location per season?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 12: Line Chart - Three-Pointers scored per winning team per season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "AvgH3=Home.groupby(\"Season\").WFGM3.mean()\n",
    "\n",
    "AvgA3=Away.groupby(\"Season\").WFGM3.mean()\n",
    "\n",
    "AvgN3=Neutral.groupby(\"Season\").WFGM3.mean()\n",
    "\n",
    "A=plt.plot(AvgH3.index,AvgH3)\n",
    "B=plt.plot(AvgA3.index,AvgA3)\n",
    "C=plt.plot(AvgN3.index,AvgN3)\n",
    "\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Three-pointers scored per season')\n",
    "plt.title('Three-pointers scored per winning team', size=20)\n",
    "plt.legend([\"Home\", \"Away\",\"Neutral\"],loc=0)\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threepointers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "There seems to be a general upward trend in three pointers scored as the years go by.It can also be observed for most seasons the number of three-pointers scored by the winning team while playing at home is greater than three-pointers scored when playing at an away, or a neutral location. Some of the reasons  for this general increase in three-pointers could be the game of basketball is evolving to more teams scoring more three pointers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **What is the average amount of  turnovers per season?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 13: Line Chart - Turnovers conceded per winning team per season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "AvgHTO=Home.groupby(\"Season\").WTO.mean()\n",
    "\n",
    "AvgATO=Away.groupby(\"Season\").WTO.mean()\n",
    "\n",
    "AvgNTO=Neutral.groupby(\"Season\").WTO.mean()\n",
    "\n",
    "\n",
    "ATO=plt.plot(AvgHTO.index,AvgHTO)\n",
    "BTO=plt.plot(AvgATO.index,AvgATO)\n",
    "CTO=plt.plot(AvgNTO.index,AvgNTO)\n",
    "\n",
    "\n",
    "plt.xlabel('Season Progression')\n",
    "plt.ylabel('Turnover per season')\n",
    "plt.title(' Turnover per winning team', size=20)\n",
    "plt.legend([\"Home\", \"Away\",\"Neutral\"],loc=0)\n",
    "plt.show() ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turnover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "For all seasons the number of turnovers conceded while playing at an away location for the winning team is greater than turnovers conceded when playing at an home or a neutral location. There also seems to be a decrease in number of turnovers through the years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **What is the ranking of the top 15 teams based on the winning percentage per season? Winning Percentage is defined as (matches won/total matches played *100)**\n",
    "\n",
    "## #Code 14: Bar Chart - Ranking top 15 teams by win percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "``` python w=pd.DataFrame(capstone[\"WTeamName\"].value_counts())\n",
    "l=pd.DataFrame(capstone[\"LTeamName\"].value_counts())\n",
    "Winning_teams = w.rename(columns={\"WTeamName\":\"Matches Played\"})\n",
    "Winning_teams[:15]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "\n",
    "Losing_teams = l.rename(columns={\"LTeamName\":\"Matches Played\"})\n",
    "Losing_teams[:15]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losingteam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pc_dict={team:w.loc[team][0]/(l.loc[team][0]+w.loc[team][0]) * 100 for team in w.index}\n",
    "\n",
    "pc_dict_counter =Counter(pc_dict)\n",
    "team=[]\n",
    "percentage=[]\n",
    "for item in pc_dict_counter.most_common(15):\n",
    "    team.append(item[0])\n",
    "    percentage.append(item[1])\n",
    "\n",
    "team.reverse()\n",
    "percentage.reverse()\n",
    "plt.barh(team,percentage)\n",
    "plt.title(\"Top 15 teams ranked by Win Percentage\")\n",
    "plt.ylabel(\"Team\")\n",
    "plt.xlabel(\"Percentages\")\n",
    "plt.tight_layout()\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rank percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team with the highest win percentage is Gonzaga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon exploration of the data and making initial observations about the  data, the next step will be to  find out whether there are any correlations within the in game statistics, and also confirm whether our initial observations were statistically significant. The questions that will be asked of the data will be:\n",
    "\n",
    "1. Is the difference between a team winning college basketball matches at home locations statistically significant from when playing at away or a neutral location? This question will be answered with the aid of an ANOVA (Analysis of Variance) test, followed by a pairwise Tukey HSD correlation.\n",
    "2. Is there a correlation between the game by game data for a winning team? A heat map analysis will be conducted on the data to find correlations between the game by game data.The correlation matrix from the heat data will show the correlations that exist between in game statistics during the season.\n",
    "3. What is the 95% confidence interval for the difference between the standard deviations of the winning scores for the two top performing teams? This analysis will be done with a bootstrap sampling analysis, calculating these differences over 10000 replicates. The teams being considered will be Gonzaga and Kansas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Is the difference between a team winning college basketball matches at home locations statistically significant from when playing at away or a neutral location? This question will be answered with the aid of an ANOVA (Analysis of Variance) test, followed by a pairwise Tukey HSD correlation.__\n",
    "\n",
    "When comparing more than three numerical datasets, the best way to preserve a Type I error probability of 0.05 is to use ANOVA. ANOVA (Analysis of Variance) tests the null hypothesis that all of the datasets have the same mean. If we reject the null hypothesis with ANOVA, we’re saying that at least one of the sets has a different mean; however, it does not tell us which datasets are different.\n",
    "We can use the SciPy function f_oneway to perform ANOVA on multiple datasets of winning scores of teams playing in home, away and neutral locations. The f_oneway function takes in each dataset as a different input and returns the t-statistic and the p-value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 15: ANOVA test & Tukey HSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python Home=capstone.loc[lambda dfH: dfH['WLoc'] == \"H\", :]\n",
    "Away=capstone.loc[lambda dfH: dfH['WLoc'] == \"A\", :]\n",
    "Neutral=capstone.loc[lambda dfN: dfN['WLoc'] == \"N\", :]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing more than two numerical datasets, the best way to preserve a Type I error probability of 0.05 is to use ANOVA. ANOVA (Analysis of Variance) tests the null hypothesis that all of the datasets have the same mean. If we reject the null hypothesis with ANOVA, we’re saying that at least one of the sets has a different mean; however, it does not tell us which datasets are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python Home_Win_mean=Home[\"WScore\"].mean\n",
    "Away_Win_mean=Away[\"WScore\"].mean\n",
    "Neutral_Win_mean=Neutral[\"WScore\"].mean\n",
    "a=Home[\"WScore\"]\n",
    "b=Away[\"WScore\"]\n",
    "c=Neutral[\"WScore\"] ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the SciPy function f_oneway to perform ANOVA on multiple datasets. It takes in each dataset as a different input and returns the t-statistic and the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python fstat, pval = f_oneway(a, b, c)\n",
    "print (pval)\n",
    "```\n",
    "\n",
    "3.94760085742195e-223 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis, in this case, is that all three populations have the same mean score on this videogame. We will reject this null hypothesis (since we are getting a p-value less than 0.05), we are reasonably confident that a pair of datasets is significantly different. After using only ANOVA, we can’t make any conclusions on which two populations between the Home, Away and Neutral locations have a significant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "python v = np.concatenate([a, b, c])\n",
    "labels = ['a'] * len(a) + ['b'] * len(b) + ['c'] * len(c)\n",
    "\n",
    "tukey_results= pairwise_tukeyhsd(v, labels, 0.05)\n",
    "\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0 = all three locations have the same mean score in the basketball game \n",
    "H1 = at least one of the locations have different means  in the basketball game.\n",
    "\n",
    " \n",
    "We will reject this null hypothesis  for the pairs a & b and a & c (since we are getting a p-value less than 0.05).  We are reasonably confident that a pair of datasets is statistically significantly different. After using only ANOVA, we can’t make any conclusions on which two populations between the home, away and neutral locations have a significant difference.\n",
    "There is a significant difference between the pairs home and away games,and the pairs home and neutral games, but there is not a significant difference between the pair away and neutral games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Is there a correlation between the game by game data for a winning team? A heat map analysis will be conducted on the data to find correlations between the game by game data.The correlation matrix from the heat data will show the correlations that exist between in game statistics during the season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7,7 \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(color_codes=True, font_scale=1.2) ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Is there a correlation between the game by game data for a winning team? A heat map analysis will be conducted on the data to find correlations between the game by game data.The correlation matrix from the heat data will show the correlations that exist between in game statistics during the season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find a correlation between variables for the winning team, a heatmap will be created. This heat map will display the r correlation and will also exclude correlations that have a p value less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` def corr_sig(df=None):\n",
    "    p_matrix = np.zeros(shape=(capstone_drop.shape[1],\n",
    "                               capstone_drop.shape[1]))\n",
    "    for col in df.columns:\n",
    "        for col2 in capstone_drop.drop(col,axis=1).columns:\n",
    "            _ , p = stats.pearsonr(capstone_drop[col],\n",
    "                                   capstone_drop[col2])\n",
    "            p_matrix[capstone_drop.columns.to_list().index(col),\n",
    "                     capstone_drop.columns.to_list().index(col2)] = p\n",
    "    return p_matrix\n",
    "\n",
    "p_values = corr_sig(capstone_drop)\n",
    "mask = np.invert(np.tril(p_values<0.05))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```def plot_cor_matrix(corr, mask=None):\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "    sns.heatmap(corr, ax=ax,\n",
    "                mask=mask,\n",
    "                # cosmetics\n",
    "                annot=True, vmin=-1, vmax=1, center=0,\n",
    "                cmap='coolwarm', linewidths=2, linecolor='black', cbar_kws={'orientation': 'horizontal'})```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap was conducted for in-game data  variables for the winning team. In the heat map displayed below orange means positive, and  blue means negative. The stronger the color, the larger the correlation magnitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```corr = capstone_drop.corr() # get correlation\n",
    "p_values = corr_sig(capstone_drop)   # get p-Value\n",
    "mask = np.invert(np.tril(p_values<0.05))# mask - only get sigificant corrplot_cor_matrix(corr,mask)\n",
    "plot_cor_matrix(corr,mask)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap represents the collinearity of the multiple variables in the dataset. The .corr() function was used in the code to show the correlation between the values. This is where we want to set our independent or target variable. Our target variable is “WScore”. This is  the number of points scored by the winning team.  We want to find out how all of the other variables affect the points scored by the winning team. In the heatmap, the dark red areas represent a positive correlation, while light blue represents a negative correlation. It is also normal that the darkest areas are a 1:1 ratio since WScore=WScore, NumOT=NumOT, etc.\n",
    "While WScore is still our independent variable, we can see in the map below that there is little to no correlation between the WTO  (-0.018), though a high correlation between WFGM and WAst (0.82, 0.56). these relationships are obvious (assists in a basketball game and field goals made positively correlates with the scores in a match) \n",
    "Features with high correlation are more linearly dependent and hence have almost the same effect on the dependent variable. So, when two features have high correlation, we can drop one of the two features. In order to decide to find which features to drop when we decide to create our machine learning model, we compare the relationship between WFGM and WAst, and we get a correlation number of (0.63). Dropping either of these variables when tuning our eventual machine model should still produce a fairly accurate prediction model.\n",
    "In addition to plotting the correlation coefficients in the heat map, only significant p-value correlations (alpha < .05) were plotted. This was achieved with the def corr_sig function. It can be seen from the plot that the relationship between WFGA3 and WPF was not statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 17: Pair plot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairs plot allows us to see both the distribution of single variables and relationships between two variables. A scan through of the pairs plot shows variables that are highly correlated with each other. The relationship between (WScore and WFGM), and (WFTA and WFTM) shows a linear correlation between these variables. This positive correlation was also confirmed with the heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "stats.pearsonr(capstone_drop[\"WPF\"],capstone_drop[\"WFGA3\"])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the 95% confidence interval for the difference between the standard deviations of the winning scores for the two top performing teams? This analysis will be done with a bootstrap sampling analysis, calculating these differences over 10000 replicates. The teams being considered will be Gonzaga and Kansas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bootstrap method will be used to compare  the means of winning scores of two teams over multiple seasons. The two chosen are Gonzaga and Kansas. These two teams were chosen because they have the highest winning percentages i.e. winning Percentage is defined as (matches won/total matches played *100) . We will proceed by defining both the null and the alternative hypothesis for our calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: there is no difference in standard deviations in the winning scores between Kansas and Gonzaga \n",
    "Ha: there is a difference in standard deviations in the winning scores between Kansas and Gonzaga \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\"\"\"\"Draw bootstrap replicates. \n",
    "    Func refers to the type of statistic we want (np.mean / np.median etc.)\"\"\"\n",
    "\n",
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates =  np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size): \n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = func(bs_sample)  \n",
    "    return bs_replicates```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first thing to do is to associate TeamID to the name of the team. \n",
    "#This will help us put a name to the team\n",
    "dic = {}\n",
    "for i in range(0,len(cap[\"TeamID\"])):\n",
    "    dic[cap[\"TeamID\"][i]]=cap['TeamNameSpelling'][i]\n",
    "capstone[\"WTeamName\"]=[dic[teamid] for teamid in capstone['WTeamID']]\n",
    "capstone[\"LTeamName\"]=[dic[teamid] for teamid in capstone['LTeamID']]\n",
    "# Creating the two subset samples of charges to Gonzaga and Kansas \n",
    "#group in arrays\n",
    "\n",
    "kansas=np.array(capstone[capstone['WTeamName']=='kansas'].WScore)\n",
    "Gonzaga=np.array(capstone[capstone['WTeamName']=='gonzaga'].WScore)\n",
    "\n",
    "# Calculating the difference in standard deviations between \n",
    "#Gonzaga and Kansas winning scores\n",
    "Gonzaga_std = np.std(Gonzaga,ddof=1)\n",
    "kansas_std = np.std(kansas,ddof=1)\n",
    "std_diff = Gonzaga_std - kansas_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.seed(47)\n",
    "\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "\n",
    "    # Concatenate the data sets: data\n",
    "    data = np.concatenate((data1, data2))\n",
    "\n",
    "    # Permute the concatenated array: permuted_data\n",
    "    permuted_data = np.random.permutation(data)\n",
    "\n",
    "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "\n",
    "    return perm_sample_1, perm_sample_2\n",
    "\n",
    "# Initializing replicates\n",
    "perm_replicates = np.empty(10000)\n",
    "\n",
    "# Generating replicates\n",
    "for i in range(10000):\n",
    "    perm_sample_1, perm_sample_2 = permutation_sample(Gonzaga, kansas)\n",
    "    perm_replicates[i] = np.std(perm_sample_1) - np.std(perm_sample_2)\n",
    "\n",
    "conf_int_lower = np.percentile(perm_replicates, 2.5)\n",
    "conf_int_upper = np.percentile(perm_replicates, 97.5)\n",
    "p = np.sum(perm_replicates >=std_diff) / len(perm_replicates)\n",
    "\n",
    "print(\"Stardard Deviation: \",std_diff )\n",
    "print(\"p-value =\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stardard Deviation:  0.49203269586884524\n",
    "p-value = 0.1687"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.seed(47)\n",
    "\n",
    "# Computing the difference in means\n",
    "mean_diff = np.mean(Gonzaga) - np.mean(kansas)\n",
    "\n",
    "# Concatenating the two samples\n",
    "conc_mean = np.mean(np.concatenate((Gonzaga, kansas)))\n",
    "\n",
    "# Shifting the means of both samples to match the concatenated mean\n",
    "Gonz_shifted = Gonzaga + conc_mean - np.mean(Gonzaga)\n",
    "kansas_shifted = kansas + conc_mean - np.mean(kansas)\n",
    "\n",
    "# Initializing replicates \n",
    "bs_replicates = np.empty(10000)\n",
    "\n",
    "# Generating replicates\n",
    "for i in range(10000):\n",
    "    Gonz_rep = np.random.choice(Gonz_shifted, size=len(Gonzaga))\n",
    "    kansas_rep = np.random.choice(kansas_shifted, size=len(kansas))\n",
    "    bs_replicates[i] = np.mean(Gonz_rep) - np.mean(kansas_rep)\n",
    "\n",
    "# Computing confidence intervals\n",
    "conf_int_lower1 = np.percentile(bs_replicates, 2.5)\n",
    "conf_int_upper1 = np.percentile(bs_replicates, 97.5)\n",
    "# Print the confidence interval\n",
    "print('95% confidence interval =', conf_int_lower1,conf_int_upper1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% confidence interval = -1.4236463156146701 1.4045422356365809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the bootstrap replicates from the shifted dataset\n",
    "bs_replicates_Gonzaga= draw_bs_reps(Gonz_shifted, np.mean, size=1000)\n",
    "bs_replicates_kansas = draw_bs_reps(kansas_shifted, np.mean, size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bsdiff = bs_replicates_Gonzaga - bs_replicates_kansas\n",
    "\n",
    "#Get the observed difference from the actual dataset\n",
    "obs_diff = np.mean(Gonzaga) - np.mean(kansas)\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7096446502178111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing p-value\n",
    "p = np.sum(bs_replicates >= mean_diff) / len(bs_replicates)\n",
    "print(\"p-value =\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value = 0.1643"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7096446502178111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the histogram of bootsrapped differences in means\n",
    "plt.hist(bs_replicates, bins=100)\n",
    "plt.axvline(mean_diff, linestyle=\"--\")\n",
    "plt.axvline(-mean_diff, linestyle=\"--\")\n",
    "plt.axvline(conf_int_lower1, color='red')\n",
    "plt.axvline(conf_int_upper1, color='red')\n",
    "plt.xlabel('Difference in means')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of differences in means between shifted bootstrapped replicates \\\n",
    "of Gonzaga and Kansas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solid red vertical lines correspond to the 95% lower and upper confidence intervals of expected random differences in means of bootstrap replicates of Gonzaga and Kansas samples. The dashed blue vertical lines correspond to the observed difference in means between Gonzaga and Kansas samples. \n",
    "Our Null and Alternative Hypothesis were as follows:\n",
    "H0 : there is no statistically significant difference in the means of the winning scores between Kansas and Gonzaga \n",
    "Ha : there is a statistically significant difference in the means of the winning scores between Kansas and Gonzaga \n",
    "The calculated p value of 0.16 is greater than the significance value of 0.05 i.e. 0.16>0.05. Therefore we fail to reject the null hypothesis, and say there is no statistically significant difference in the means of the winning scores between Kansas and Gonzaga. \n",
    "Our bootstrap replicates with a 95% confidence interval indicate that the difference in means between the two groups have a 95% chance of lying within [-1.4236463156146701 , 1.4045422356365809]. Our calculated difference in means is 0.71. Since the value is within the 95% confidence range, we therefore fail to reject the null hypothesis, and say there is no statistically significant difference in means between the Kansas and Gonzaga winning scores.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
